Name: Haoliang Chang

Tel: (+852) 52265021

Email: <hlchang4-c@my.cityu.edu.hk>  

GitHub: <https://github.com/bright1993ff66>  

Date of Birth: 1993-02-17  

## Research Interests

+ **Social Media Data Analysis and Its Application in Transportation and Urban Planning**
  - Traffic-related Social Media Data Detection, GIS analysis and Traffic Information Characterization
  - Social Media Community Detection and Profiling

+ **Natural Language Processing**  
  - Context Representation Learning (words, sentences, documents)
  - Application of Context Representation in Downstream Tasks such as Text Classification and Information Extraction


## Education

+ **2018.09 - Now**   
**City University of Hong Kong, Hong Kong, China**   
PhD Student

+ **2015.09 - 2016.09**  
**The University of Edinburgh, Scotland, UK**  
MSc. Statistics and Operational Research 
	- Overall Classification of the Qualification: With Distinction	
	- Average Points: 77/100

+ **2011.09 - 2015.06**  
  **Beifang University of Nationalities, Ningxia, China**  
  BSc. Statistics
  - Recipient of Chinese National Scholarship(2011-2012)
  - Average Points: 88/100

## Research Experience

- **2020.5 - Now**  
  **Traffic Relevant Weibo Detection and Analysis in Shanghai**
  - Use [Weibo API](https://open.weibo.com/wiki/API) to crawl the Weibos posted near Shanghai in 2012 
  - Manually label the collected Weibos and train the deep learning models such as ```CNN-LSTM``` and ```Transformer``` based models to detect the traffic relevant Weibos
  - Based on the detected traffic relevant microblogs, conduct traffic relevant Weibo analysis, characterize the areas with high density of traffic events through text mining
- **2020.3 - Now**  
  **Traffic Information Recommendation Using Graph Neural Networks**
  - Use [Twitter API](https://developer.twitter.com/en/docs) to collect tweets posted in major US cities in 2018
  - Based on user's historical interaction with traffic relevant messages in social media, build the graph between the social media users and places
  - Use Graph Attention Network to encode the user-place graph and make traffic information recommendation
- **2018.11 - 2020.5**  
  **Evaluated the Influence of New Transit Stations on Nearby People in Hong Kong**
  - Used  [Twitter API](https://developer.twitter.com/en/docs) to collect tweets posted in Hong Kong from May 2016 to December 2018
  - Run [ArcGIS](https://www.esri.com/en-us/arcgis/products/arcgis-online/overview) to find the tweets posted in the walkable distance (500 meter) around the new transit stations
  - Applied sentiment analysis to estimate the sentiment of tweets posted near transit stations. Evaluated the influence of new transit stations on nearby people by comparing the sentiment and number of posted tweets before and after the introduction of transit stations

## Project Experience

- **2018.10 - Now**  
  **Crawl and Manage the Tweets Posted in 27 Cities Worldwide**
  - Set up [Amazon EC2](https://aws.amazon.com/ec2/?ec2-whats-new.sort-by=item.additionalFields.postDateTime&ec2-whats-new.sort-order=desc) instances and used [Twitter Streaming API](https://developer.twitter.com/en/docs) to collect the tweets posted in major cities worldwide, including US cities(Atlanta, Boston, Chicago, etc.), European Cities(London, Madrid, etc.), and other major cities(Taipei, Bangkok, Tokyo, etc)
  - Monitor the tweet collection process on a daily basis
  - Saved the collected tweets to [Amazon S3](https://aws.amazon.com/s3/) and local server for the following research
- **2020.8-2020.9**  
  **Find the Tweets Posted in Singapore Open Space**
  - Crawled the land use data from [OpenStreetMap](https://www.openstreetmap.org/#map=11/22.3567/114.1363) in Singapore
  - Run Python scripts to get tweets with geo-information
  - Used the [Spatial Join](https://pro.arcgis.com/en/pro-app/tool-reference/analysis/spatial-join.htm) method in ```arcpy``` to find the tweets posted in Singapore open space such as amusement parks, playgrounds and green space


## Work Experience

+ **2016.10 - 2017.04** Research Executive  
  **Department of Automobile, Ipsos Beijing, China**  
  + Specialized in the research of whole automobile market and market segment, the evaluation of product and its positioning, the analysis of competitors, etc.
  + Used popular Python based modules such as ```nltk```, ```gensim```, and ```sklearn``` to do sentiment analysis of customers' web comments on popular Chinese car brands 
  + Used R packages (```rvest```, ```RCurl```, etc.) to design web crawler from scratch and got useful raw data. Completed data visualization tasks using popular R packages(```ggplot2```, ```corrplot```, etc.)
  + Participated in the on-site market research project, designed the questionnaire, discussed with car buyers about the automobile market and car models, and wrote the project report for clients from automobile industry

## Skills

+ **Language:** Chinese(Native Speaker), English, Spanish(Basic)
+ **Programming Languages:** Python, R, SQL
+ **Framework:** ```Tensorflow```, ```PyTorch```, ```NLTK```, ```SpaCy```, ```Gensim```, ```DGL```, ```networkx```
+ **GIS Analysis:** ArcGIS, python ```arcpy```
+ **Productivity Tools:** LaTex, Markdown, Git, Vim, PyCharm

## Person

+ Write articles about PhD application on [Jianshu](https://www.jianshu.com/u/0c6ccae5639b)
