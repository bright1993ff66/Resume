Name: Haoliang Chang

Tel: (+852) 52265021

Email: <hlchang4-c@my.cityu.edu.hk>  

GitHub: <https://github.com/bright1993ff66>  

Date of Birth: 1993-02-17  

## Research Interests

+ **Social Media Data Analysis and Its Application in Smart Cities**  
  - Traffic-related Social Media Data Detection, GIS analysis and Traffic Information Characterization
  - Social Media Community Detection and Profiling

+ **Natural Language Processing**  
  - Context Representation Learning (words, sentences, documents)
  - Application of Context Representation in Downstream Tasks such as Text Classification and Information Extraction


## Education

+ **2018.09 - Now**   
**City University of Hong Kong, Hong Kong, China**   
PhD Student

+ **2015.09 - 2016.09**  
**The University of Edinburgh, Scotland, UK**  
MSc. Statistics and Operational Research 
	- Overall Classification of the Qualification: With Distinction	
	- Average Points: 77/100

+ **2011.09 - 2015.06**  
  **Beifang University of Nationalities, Ningxia, China**  
  BSc. Statistics
  - Recipient of Chinese National Scholarship(2011-2012)
  - Average Points: 88/100

## Research Experience

+ **2017.08 - 2017.11**  
**Natural Language Processing based Recommender System**
	- Based on a Coursera corpus, used language models such as LSI and LDA to recommend courses to Coursera learners  
	
+ **2016.10 - 2017.05**   
**Sentiment Analysis of Movie Reviews in NLTK Movie Reviews Corpora**
	- Firstly used basic machine learning methods(Na√Øve Bayes, logistics regression, SVM, etc.) to classify the sentiments 
	- Then implemented word embeddings, MLP classifier, etc. to solve the sentiment analysis problem

+ **2016.05 - 2016.08**   
**Application of Empirical Likelihood for Statistical Analysis(MSc. dissertation)**
	- Implemented empirical likelihood method on various datasets and made relevant statistical inference from univariate mean to regression parameters 
	- Successfully proved that the empirical likelihood approach was more data-oriented than the parametric methods 

## Project Experience

- **2018.10 - Now**  
  **Crawl and Manage the Tweets Posted in 27 Cities Worldwide**
  - Set up [Amazon EC2](https://aws.amazon.com/ec2/?ec2-whats-new.sort-by=item.additionalFields.postDateTime&ec2-whats-new.sort-order=desc) instances and used [Twitter Streaming API](https://developer.twitter.com/en/docs) to collect the tweets posted in major cities worldwide, including US cities(Atlanta, Boston, Chicago, etc.), European Cities(London, Madrid, etc.), and other major cities(Taipei, Bangkok, Tokyo, etc)
  - Monitor the tweet collection process on a daily basis
  - Saved the collected tweets to [Amazon S3](https://aws.amazon.com/s3/) and local server for the following analysis


## Work Experience

+ **2016.10 - 2017.04** Research Executive  
**Department of Automobile, Ipsos Beijing, China**  
- Specialized in the research of whole automobile market and market segment, the evaluation of product and its positioning, the analysis of competitors, etc.
	- Used popular Python based modules such as ```nltk```, ```gensim```, and ```sklearn``` to do sentiment analysis of customers' web comments on popular Chinese car brands 
	- Used R packages (```rvest```, ```RCurl```, etc.) to design web crawler from scratch and got useful raw data. Completed data visualization tasks using popular R packages(```ggplot2```, ```corrplot```, etc.)

## Skills

+ **Language:** Chinese(Native Speaker), English, Spanish(Basic)
+ **Programming Languages:** Python, R, SQL
+ **Framework:** ```Tensorflow```, ```PyTorch```, ```NLTK```, ```SpaCy```, ```Gensim```, ```DGL```, ```networkx```
+ **Productivity Tools:** Latex, Markdown, Git, Vim, PyCharm

## Person

+ Write articles about PhD application on [Jianshu](https://www.jianshu.com/u/0c6ccae5639b)
